{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 1000,
  "global_step": 10185,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0589253489485508,
      "grad_norm": 0.4472684860229492,
      "learning_rate": 7.88e-05,
      "loss": 8.5348,
      "step": 200
    },
    {
      "epoch": 0.1178506978971016,
      "grad_norm": 0.21354475617408752,
      "learning_rate": 0.00015840000000000003,
      "loss": 1.5194,
      "step": 400
    },
    {
      "epoch": 0.1767760468456524,
      "grad_norm": 0.20658129453659058,
      "learning_rate": 0.00019801755291688178,
      "loss": 1.2979,
      "step": 600
    },
    {
      "epoch": 0.2357013957942032,
      "grad_norm": 0.38242655992507935,
      "learning_rate": 0.00019388745482705214,
      "loss": 1.2194,
      "step": 800
    },
    {
      "epoch": 0.294626744742754,
      "grad_norm": 0.2813790738582611,
      "learning_rate": 0.00018975735673722253,
      "loss": 1.1923,
      "step": 1000
    },
    {
      "epoch": 0.3535520936913048,
      "grad_norm": 0.24097977578639984,
      "learning_rate": 0.00018562725864739287,
      "loss": 1.1723,
      "step": 1200
    },
    {
      "epoch": 0.41247744263985564,
      "grad_norm": 0.23562459647655487,
      "learning_rate": 0.00018149716055756326,
      "loss": 1.1603,
      "step": 1400
    },
    {
      "epoch": 0.4714027915884064,
      "grad_norm": 0.2663145065307617,
      "learning_rate": 0.00017736706246773362,
      "loss": 1.1338,
      "step": 1600
    },
    {
      "epoch": 0.5303281405369572,
      "grad_norm": 0.21060511469841003,
      "learning_rate": 0.00017323696437790398,
      "loss": 1.1144,
      "step": 1800
    },
    {
      "epoch": 0.589253489485508,
      "grad_norm": 0.35672104358673096,
      "learning_rate": 0.00016910686628807435,
      "loss": 1.1086,
      "step": 2000
    },
    {
      "epoch": 0.6481788384340589,
      "grad_norm": 0.22968824207782745,
      "learning_rate": 0.00016497676819824474,
      "loss": 1.092,
      "step": 2200
    },
    {
      "epoch": 0.7071041873826096,
      "grad_norm": 0.21636748313903809,
      "learning_rate": 0.00016084667010841507,
      "loss": 1.1017,
      "step": 2400
    },
    {
      "epoch": 0.7660295363311604,
      "grad_norm": 0.22592802345752716,
      "learning_rate": 0.00015671657201858546,
      "loss": 1.0804,
      "step": 2600
    },
    {
      "epoch": 0.8249548852797113,
      "grad_norm": 0.259725421667099,
      "learning_rate": 0.00015258647392875582,
      "loss": 1.0753,
      "step": 2800
    },
    {
      "epoch": 0.8838802342282621,
      "grad_norm": 0.1997951716184616,
      "learning_rate": 0.0001484563758389262,
      "loss": 1.0787,
      "step": 3000
    },
    {
      "epoch": 0.9428055831768128,
      "grad_norm": 0.2190091609954834,
      "learning_rate": 0.00014432627774909655,
      "loss": 1.0629,
      "step": 3200
    },
    {
      "epoch": 1.0014731337237137,
      "grad_norm": 0.2298985868692398,
      "learning_rate": 0.0001401961796592669,
      "loss": 1.0631,
      "step": 3400
    },
    {
      "epoch": 1.0603984826722646,
      "grad_norm": 0.3305152952671051,
      "learning_rate": 0.00013606608156943728,
      "loss": 1.0531,
      "step": 3600
    },
    {
      "epoch": 1.1193238316208154,
      "grad_norm": 0.27091971039772034,
      "learning_rate": 0.00013193598347960764,
      "loss": 1.0477,
      "step": 3800
    },
    {
      "epoch": 1.1782491805693662,
      "grad_norm": 0.22579948604106903,
      "learning_rate": 0.00012780588538977803,
      "loss": 1.035,
      "step": 4000
    },
    {
      "epoch": 1.237174529517917,
      "grad_norm": 0.24190615117549896,
      "learning_rate": 0.00012367578729994836,
      "loss": 1.0452,
      "step": 4200
    },
    {
      "epoch": 1.296099878466468,
      "grad_norm": 0.30552881956100464,
      "learning_rate": 0.00011954568921011875,
      "loss": 1.0402,
      "step": 4400
    },
    {
      "epoch": 1.3550252274150185,
      "grad_norm": 0.23239673674106598,
      "learning_rate": 0.0001154155911202891,
      "loss": 1.0509,
      "step": 4600
    },
    {
      "epoch": 1.4139505763635694,
      "grad_norm": 0.23363730311393738,
      "learning_rate": 0.00011128549303045948,
      "loss": 1.0327,
      "step": 4800
    },
    {
      "epoch": 1.4728759253121202,
      "grad_norm": 0.2596004009246826,
      "learning_rate": 0.00010715539494062986,
      "loss": 1.0367,
      "step": 5000
    },
    {
      "epoch": 1.531801274260671,
      "grad_norm": 0.21892878413200378,
      "learning_rate": 0.0001030252968508002,
      "loss": 1.0201,
      "step": 5200
    },
    {
      "epoch": 1.5907266232092219,
      "grad_norm": 0.22869524359703064,
      "learning_rate": 9.889519876097058e-05,
      "loss": 1.0218,
      "step": 5400
    },
    {
      "epoch": 1.6496519721577725,
      "grad_norm": 0.3540360927581787,
      "learning_rate": 9.476510067114094e-05,
      "loss": 1.0102,
      "step": 5600
    },
    {
      "epoch": 1.7085773211063233,
      "grad_norm": 0.21603479981422424,
      "learning_rate": 9.06350025813113e-05,
      "loss": 1.0082,
      "step": 5800
    },
    {
      "epoch": 1.7675026700548742,
      "grad_norm": 0.218811497092247,
      "learning_rate": 8.650490449148167e-05,
      "loss": 1.0035,
      "step": 6000
    },
    {
      "epoch": 1.826428019003425,
      "grad_norm": 0.23025180399417877,
      "learning_rate": 8.237480640165203e-05,
      "loss": 1.0134,
      "step": 6200
    },
    {
      "epoch": 1.8853533679519758,
      "grad_norm": 0.24078655242919922,
      "learning_rate": 7.824470831182241e-05,
      "loss": 1.015,
      "step": 6400
    },
    {
      "epoch": 1.9442787169005267,
      "grad_norm": 0.21534907817840576,
      "learning_rate": 7.411461022199277e-05,
      "loss": 0.9934,
      "step": 6600
    },
    {
      "epoch": 2.0029462674474274,
      "grad_norm": 0.2189425826072693,
      "learning_rate": 6.998451213216313e-05,
      "loss": 1.0016,
      "step": 6800
    },
    {
      "epoch": 2.0618716163959783,
      "grad_norm": 0.2294306457042694,
      "learning_rate": 6.585441404233351e-05,
      "loss": 1.0104,
      "step": 7000
    },
    {
      "epoch": 2.120796965344529,
      "grad_norm": 0.24126125872135162,
      "learning_rate": 6.172431595250387e-05,
      "loss": 0.9942,
      "step": 7200
    },
    {
      "epoch": 2.17972231429308,
      "grad_norm": 0.2396986186504364,
      "learning_rate": 5.7594217862674235e-05,
      "loss": 0.998,
      "step": 7400
    },
    {
      "epoch": 2.238647663241631,
      "grad_norm": 0.4180700480937958,
      "learning_rate": 5.346411977284461e-05,
      "loss": 0.9938,
      "step": 7600
    },
    {
      "epoch": 2.2975730121901816,
      "grad_norm": 0.21838858723640442,
      "learning_rate": 4.9334021683014974e-05,
      "loss": 0.9834,
      "step": 7800
    },
    {
      "epoch": 2.3564983611387325,
      "grad_norm": 0.2539534866809845,
      "learning_rate": 4.520392359318534e-05,
      "loss": 0.9968,
      "step": 8000
    },
    {
      "epoch": 2.4154237100872833,
      "grad_norm": 0.25610557198524475,
      "learning_rate": 4.107382550335571e-05,
      "loss": 1.0085,
      "step": 8200
    },
    {
      "epoch": 2.474349059035834,
      "grad_norm": 0.22008079290390015,
      "learning_rate": 3.6943727413526076e-05,
      "loss": 0.9952,
      "step": 8400
    },
    {
      "epoch": 2.5332744079843845,
      "grad_norm": 0.3454281687736511,
      "learning_rate": 3.281362932369644e-05,
      "loss": 0.9962,
      "step": 8600
    },
    {
      "epoch": 2.592199756932936,
      "grad_norm": 0.23277609050273895,
      "learning_rate": 2.8704181724315952e-05,
      "loss": 0.9959,
      "step": 8800
    },
    {
      "epoch": 2.651125105881486,
      "grad_norm": 0.2507229745388031,
      "learning_rate": 2.457408363448632e-05,
      "loss": 0.9954,
      "step": 9000
    },
    {
      "epoch": 2.710050454830037,
      "grad_norm": 0.22780384123325348,
      "learning_rate": 2.0443985544656685e-05,
      "loss": 0.9864,
      "step": 9200
    },
    {
      "epoch": 2.768975803778588,
      "grad_norm": 0.2571141719818115,
      "learning_rate": 1.6313887454827054e-05,
      "loss": 0.9902,
      "step": 9400
    },
    {
      "epoch": 2.8279011527271387,
      "grad_norm": 0.2331838607788086,
      "learning_rate": 1.2183789364997419e-05,
      "loss": 0.9891,
      "step": 9600
    },
    {
      "epoch": 2.8868265016756895,
      "grad_norm": 0.2698637843132019,
      "learning_rate": 8.053691275167785e-06,
      "loss": 0.9905,
      "step": 9800
    },
    {
      "epoch": 2.9457518506242404,
      "grad_norm": 0.21681351959705353,
      "learning_rate": 3.9442436757873e-06,
      "loss": 0.9949,
      "step": 10000
    }
  ],
  "logging_steps": 200,
  "max_steps": 10185,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 2000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 9.95552813434798e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
