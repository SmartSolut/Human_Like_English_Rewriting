# ุฏููู ุงูุชุฏุฑูุจ ุงููุญุณูู / Enhanced Training Guide

## ุงูุชุญุณููุงุช ุงููุถุงูุฉ

### โ 1. ุงูุชูููู ุฃุซูุงุก ุงูุชุฏุฑูุจ
- ุชู ุชูุนูู `eval_strategy="steps"` ูุชูููู ุงููููุฐุฌ ุฃุซูุงุก ุงูุชุฏุฑูุจ
- ูุชู ุชูููู ุงููููุฐุฌ ูู `eval_steps` ุฎุทูุฉ
- ูุชู ุญูุธ ุฃูุถู ูููุฐุฌ ุจูุงุกู ุนูู `eval_loss`
- ุฅุถุงูุฉ `compute_metrics` ูุญุณุงุจ metrics ุฅุถุงููุฉ

### โ 2. ูุญุต ุฌูุฏุฉ ุงูุจูุงูุงุช
- ูุชู ูุญุต ุงูุจูุงูุงุช ุชููุงุฆูุงู ูุจู ุงูุชุฏุฑูุจ
- ููุงุฑู ุจูู `input` ู `target` ูุถูุงู ูุฌูุฏ ุฅุนุงุฏุฉ ุตูุงุบุฉ ูุงููุฉ
- ูุญุฐุฑ ุฅุฐุง ูุงูุช ุงูุชุบููุฑุงุช ููููุฉ ุฌุฏุงู

### โ 3. ุชุญุณูู Logging
- ุนุฑุถ ูุนูููุงุช ููุตูุฉ ุนู ุงููููุฐุฌ ุงููุญููู
- ุนุฑุถ ุญุฌู ุงููููุฐุฌ ูููุนู (LoRA vs Full)
- ุนุฑุถ ูุณุงุฑ ุงููููุงุช ุงููุณุชุฎุฏูุฉ ูู ุงูุชุฏุฑูุจ

### โ 4. ูุณุญ ุงููุงุด
- ุฅุถุงูุฉ ูุธููุฉ `clear_cache()` ููุณุญ ุงููุงุด ุงููุฏูู
- ุณูุฑูุจุช `clear_cache.bat` ููุณุญ ุงููุงุด ูุฏููุงู

---

## ุฎุทูุงุช ุงูุชุฏุฑูุจ

### ุงูุฎุทูุฉ 1: ุงูุชุญูู ูู ุงููููุฐุฌ ุงูุญุงูู

#### ุฃ) ุดุบูู API ูุงูุญุต ุงูููุฌ:
```bash
python src/api/main.py
```

ุงุจุญุซ ุนู:
```
Model Loaded Successfully!
๐ Model Path: models/final
๐ฆ Base Model: t5-base
๐ง Model Type: LoRA Adapter
๐ฆ Model Size: X.XX MB
```

#### ุจ) ุชุญูู ูู ุงููููุงุช:
- `models/final/adapter_config.json` โ LoRA adapter
- `models/final/adapter_model.safetensors` โ LoRA weights
- ุงูุญุฌู ุงููุชููุน: **5-15 MB** (ุฅุฐุง ูุงู ุฃูุจุฑุ ูุฏ ูููู ููุงู ูุดููุฉ)

---

### ุงูุฎุทูุฉ 2: ูุณุญ ุงููุงุด ุงููุฏูู

#### ุฃ) ุงุณุชุฎุฏุงู ุงูุณูุฑูุจุช:
```bash
scripts\clear_cache.bat
```

#### ุจ) ุฃู ูุฏููุงู:
```bash
# ุงุญุฐู ุงููุฌูุฏุงุช ุงูุชุงููุฉ:
data\cache\train_tokenized\
data\cache\val_tokenized\
data\cache\cache_marker.txt
```

**โ๏ธ ููู:** ูุฐุง ููุณุญ ููุท ุงููุงุดุ ูุง ููุณุญ ุงูุจูุงูุงุช ุงูุฃุตููุฉ!

---

### ุงูุฎุทูุฉ 3: ุงูุชุญูู ูู ูููุงุช ุงูุชุฏุฑูุจ

#### ุฃ) ุชุญูู ูู ุงูููู ุงููุณุชุฎุฏู:
ุงูุชุญ `scripts/train_part_1.bat` ูุชุญูู ูู:
```batch
set TRAIN_FILE=%SPLITS_DIR%\train_part_1.json
```

#### ุจ) ุฅุฐุง ููุช ุชุฑูุฏ ุงููุณุฎุฉ ุงูููุธูุฉ:
```batch
set TRAIN_FILE=%SPLITS_DIR%\train_part_1_cleaned.json
```

#### ุฌ) ูุญุต ุนููุฉ ูู ุงูุจูุงูุงุช:
```python
import json

# ุงูุชุญ ููู ุงูุชุฏุฑูุจ
with open('data/processed/splits_5_parts/train_part_1.json', 'r', encoding='utf-8') as f:
    data = json.load(f)

# ุงูุญุต ุฃูู 5 ุนููุงุช
for i, sample in enumerate(data[:5]):
    input_text = sample['input'].replace('humanize: ', '')
    target_text = sample['target']
    
    print(f"\n=== Sample {i+1} ===")
    print(f"Input: {input_text[:100]}...")
    print(f"Target: {target_text[:100]}...")
    print(f"Input words: {len(input_text.split())}")
    print(f"Target words: {len(target_text.split())}")
```

**โ ูุฌุจ ุฃู ูููู ุงููุฑู ูุงุถุญุงู ุจูู input ู target!**

---

### ุงูุฎุทูุฉ 4: ุงูุชุฏุฑูุจ ุนูู ุงูุฃุฌุฒุงุก

#### ุฃ) ุชุฏุฑูุจ ุงูุฌุฒุก ุงูุฃูู:
```bash
scripts\train_part_1.bat
```

#### ุจ) ูุฑุงูุจุฉ ุงูููุฌ:
ุงุจุญุซ ุนู:
```
Checking Data Quality
Total samples in file: XXXX
Average word changes per sample: XX.X
โ Data quality looks good - sufficient variation

Training Configuration
๐ Train file: data/processed/splits_5_parts/train_part_1.json
๐ Validation file: data/processed/mpc_cleaned_combined_val.json
๐ Train samples: X,XXX
๐ Validation samples: X,XXX

โ Evaluation enabled: eval_strategy='steps', eval_steps=XXX
โ Best model selection: metric_for_best_model='eval_loss'
```

#### ุฌ) ูุฑุงูุจุฉ Loss:
```
Step 100: train_loss=2.XXX, eval_loss=2.XXX
Step 200: train_loss=1.XXX, eval_loss=1.XXX
...
```

**โ๏ธ ุฅุฐุง ูุงู `eval_loss` ูุง ูุชูุงูุตุ ูุฏ ูููู ููุงู overfitting!**

---

### ุงูุฎุทูุฉ 5: ุงูุชุญูู ูู ุงููููุฐุฌ ุจุนุฏ ุงูุชุฏุฑูุจ

#### ุฃ) ูุญุต ุงูุญุฌู:
```
Saving Final Model
๐ Saving to: models/final
โ LoRA adapter saved successfully
๐ฆ Model size: X.XX MB
```

**โ ุงูุญุฌู ุงููุชููุน: 5-15 MB**

#### ุจ) ุฅุนุงุฏุฉ ุชุญููู ุงููููุฐุฌ:
```bash
# ุฅุนุงุฏุฉ ุชุดุบูู API
python src/api/main.py

# ุฃู ุงุณุชุฎุฏุงู endpoint
curl -X POST http://localhost:8000/api/reload-model
```

---

## ูุตุงุฆุญ ูููุฉ

### 1. ุฅุฐุง ูุงู ุงููููุฐุฌ ููุชุฌ ุชุบููุฑุงุช ุจุณูุทุฉ:

#### ุฃ) ุชุญูู ูู ุงูุจูุงูุงุช:
- ุชุฃูุฏ ุฃู ุงููุฑู ุจูู `input` ู `target` ูุจูุฑ
- ุฅุฐุง ูุงู ุงููุฑู < 10%ุ ุงููููุฐุฌ ุณูุชุนูู ุงููุณุฎ

#### ุจ) ุชุญูู ูู Loss:
- ุฅุฐุง ูุงู `eval_loss` ูุง ูุชูุงูุตุ ูุฏ ุชุญุชุงุฌ:
  - ุชูููู `learning_rate`
  - ุฒูุงุฏุฉ `num_epochs`
  - ุชุบููุฑ `lora_r` ุฃู `lora_alpha`

#### ุฌ) ุชุญูู ูู ูุนุงููุงุช ุงูุชูููุฏ:
- ูู `src/api/main.py`ุ ุฑุงุฌุน:
  - `temperature` (ุญุงูู ุฑูุนู)
  - `do_sample` (ูุนููู ูู medium)
  - `repetition_penalty` (ุญุงูู ุฑูุนู)

### 2. ุฅุฐุง ูุงู ุงูุญุฌู ูุจูุฑ (>> 15 MB):

#### ุฃ) ุชุญูู ูู ุทุฑููุฉ ุงูุญูุธ:
```python
# ูุฌุจ ุฃู ูููู:
model.save_pretrained(path)  # ูุญูุธ adapter ููุท

# ูููุณ:
model.merge_and_unload().save_pretrained(path)  # ูุญูุธ ุงููููุฐุฌ ุงููุงูู
```

#### ุจ) ุชุญูู ูู `adapter_config.json`:
```json
{
  "peft_type": "LORA",
  "r": 16,
  "lora_alpha": 32,
  ...
}
```

### 3. ุฅุฐุง ูุงู ุงูุชุฏุฑูุจ ุจุทูุก:

#### ุฃ) ููู `eval_steps`:
```python
eval_steps = 1000  # ุจุฏูุงู ูู 500
```

#### ุจ) ููู `save_steps`:
```python
save_steps = 2000  # ุจุฏูุงู ูู 1000
```

#### ุฌ) ุงุณุชุฎุฏู `eval_strategy="no"` ูุคูุชุงู:
```python
eval_strategy="no"  # ูุชุฏุฑูุจ ุฃุณุฑุน (ููู ุจุฏูู ุชูููู)
```

---

## ุงูุฃูุงูุฑ ุงูุณุฑูุนุฉ

### ูุณุญ ุงููุงุด:
```bash
scripts\clear_cache.bat
```

### ุชุฏุฑูุจ ุงูุฌุฒุก ุงูุฃูู:
```bash
scripts\train_part_1.bat
```

### ูุญุต ุงููููุฐุฌ:
```bash
python src/api/main.py
# ุซู ุงูุชุญ http://localhost:8000
```

### ุฅุนุงุฏุฉ ุชุญููู ุงููููุฐุฌ:
```bash
curl -X POST http://localhost:8000/api/reload-model
```

---

## ุงุณุชูุดุงู ุงูุฃุฎุทุงุก

### ุงููุดููุฉ: ุงููููุฐุฌ ููุชุฌ ููุณ ุงููุฏุฎู
**ุงูุญู:**
1. ุชุญูู ูู ุฌูุฏุฉ ุงูุจูุงูุงุช (ุงููุฑู ุจูู input/target)
2. ูุณุญ ุงููุงุด ูุฅุนุงุฏุฉ ุงูุชุฏุฑูุจ
3. ุฑูุน `temperature` ู `repetition_penalty`

### ุงููุดููุฉ: ุงูุญุฌู ูุจูุฑ (>> 15 MB)
**ุงูุญู:**
1. ุชุญูู ูู `adapter_config.json`
2. ุชุฃูุฏ ุฃู `save_pretrained()` ูุญูุธ adapter ููุท
3. ูุง ุชุณุชุฎุฏู `merge_and_unload()`

### ุงููุดููุฉ: Loss ูุง ูุชูุงูุต
**ุงูุญู:**
1. ุชุญูู ูู ุงูุจูุงูุงุช (ูุฏ ุชููู ูุชุดุงุจูุฉ ุฌุฏุงู)
2. ููู `learning_rate`
3. ุฒุฏ `num_epochs`
4. ุบููุฑ `lora_r` ุฃู `lora_alpha`

---

## ุงูุฎูุงุตุฉ

โ **ุชู ุฅุถุงูุฉ:**
- ุงูุชูููู ุฃุซูุงุก ุงูุชุฏุฑูุจ
- ูุญุต ุฌูุฏุฉ ุงูุจูุงูุงุช
- ุชุญุณูู logging
- ูุธููุฉ ูุณุญ ุงููุงุด

โ **ุงูุฎุทูุงุช ุงููุทููุจุฉ:**
1. ุชุญูู ูู ุงููููุฐุฌ ุงูุญุงูู
2. ูุณุญ ุงููุงุด
3. ุชุญูู ูู ูููุงุช ุงูุชุฏุฑูุจ
4. ุชุฏุฑูุจ ุนูู ุงูุฃุฌุฒุงุก
5. ุงูุชุญูู ูู ุงููููุฐุฌ ุจุนุฏ ุงูุชุฏุฑูุจ

โ **ุงููุชูุฌุฉ ุงููุชููุนุฉ:**
- ูููุฐุฌ ุจุญุฌู 5-15 MB (LoRA adapter)
- ุฅุนุงุฏุฉ ุตูุงุบุฉ ุฃูุถู (ุชุบููุฑุงุช ูุงุถุญุฉ)
- ุชูููู ุฃุซูุงุก ุงูุชุฏุฑูุจ (eval_loss)

---

**ุชุงุฑูุฎ ุงูุชุญุฏูุซ:** 2025-01-XX
**ุงูุฅุตุฏุงุฑ:** 2.0
