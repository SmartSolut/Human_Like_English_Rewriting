{
  "best_global_step": 7632,
  "best_metric": 0.9009906053543091,
  "best_model_checkpoint": "./models/checkpoints\\checkpoint-7632",
  "epoch": 2.248075719073399,
  "eval_steps": 848,
  "global_step": 7632,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0294626744742754,
      "grad_norm": 7.345534324645996,
      "learning_rate": 3.9200000000000004e-05,
      "loss": 12.7502,
      "step": 100
    },
    {
      "epoch": 0.0589253489485508,
      "grad_norm": 0.43531572818756104,
      "learning_rate": 7.840000000000001e-05,
      "loss": 4.1406,
      "step": 200
    },
    {
      "epoch": 0.0883880234228262,
      "grad_norm": 0.26097193360328674,
      "learning_rate": 0.0001184,
      "loss": 1.6072,
      "step": 300
    },
    {
      "epoch": 0.1178506978971016,
      "grad_norm": 0.22635431587696075,
      "learning_rate": 0.00015840000000000003,
      "loss": 1.4102,
      "step": 400
    },
    {
      "epoch": 0.147313372371377,
      "grad_norm": 0.29758182168006897,
      "learning_rate": 0.0001984,
      "loss": 1.3309,
      "step": 500
    },
    {
      "epoch": 0.1767760468456524,
      "grad_norm": 0.20284990966320038,
      "learning_rate": 0.00019801755291688178,
      "loss": 1.2603,
      "step": 600
    },
    {
      "epoch": 0.20623872131992782,
      "grad_norm": 0.2505047023296356,
      "learning_rate": 0.000195952503871967,
      "loss": 1.2416,
      "step": 700
    },
    {
      "epoch": 0.2357013957942032,
      "grad_norm": 0.3962065577507019,
      "learning_rate": 0.00019388745482705214,
      "loss": 1.1946,
      "step": 800
    },
    {
      "epoch": 0.2498434795418554,
      "eval_loss": 1.096681833267212,
      "eval_runtime": 52.1612,
      "eval_samples_per_second": 57.514,
      "eval_steps_per_second": 3.604,
      "step": 848
    },
    {
      "epoch": 0.2651640702684786,
      "grad_norm": 0.25619882345199585,
      "learning_rate": 0.00019182240578213732,
      "loss": 1.2066,
      "step": 900
    },
    {
      "epoch": 0.294626744742754,
      "grad_norm": 0.275122731924057,
      "learning_rate": 0.00018975735673722253,
      "loss": 1.1757,
      "step": 1000
    },
    {
      "epoch": 0.32408941921702944,
      "grad_norm": 0.22223085165023804,
      "learning_rate": 0.0001876923076923077,
      "loss": 1.1619,
      "step": 1100
    },
    {
      "epoch": 0.3535520936913048,
      "grad_norm": 0.23597563803195953,
      "learning_rate": 0.00018562725864739287,
      "loss": 1.1824,
      "step": 1200
    },
    {
      "epoch": 0.3830147681655802,
      "grad_norm": 0.20862002670764923,
      "learning_rate": 0.00018356220960247808,
      "loss": 1.1565,
      "step": 1300
    },
    {
      "epoch": 0.41247744263985564,
      "grad_norm": 0.251874178647995,
      "learning_rate": 0.00018149716055756326,
      "loss": 1.1643,
      "step": 1400
    },
    {
      "epoch": 0.44194011711413106,
      "grad_norm": 0.25299596786499023,
      "learning_rate": 0.00017943211151264844,
      "loss": 1.1437,
      "step": 1500
    },
    {
      "epoch": 0.4714027915884064,
      "grad_norm": 0.2410474419593811,
      "learning_rate": 0.00017736706246773362,
      "loss": 1.1232,
      "step": 1600
    },
    {
      "epoch": 0.4996869590837108,
      "eval_loss": 1.0204124450683594,
      "eval_runtime": 52.0922,
      "eval_samples_per_second": 57.59,
      "eval_steps_per_second": 3.609,
      "step": 1696
    },
    {
      "epoch": 0.5008654660626818,
      "grad_norm": 0.20664528012275696,
      "learning_rate": 0.0001753020134228188,
      "loss": 1.1065,
      "step": 1700
    },
    {
      "epoch": 0.5303281405369572,
      "grad_norm": 0.2114935964345932,
      "learning_rate": 0.00017323696437790398,
      "loss": 1.123,
      "step": 1800
    },
    {
      "epoch": 0.5597908150112326,
      "grad_norm": 0.2068428248167038,
      "learning_rate": 0.00017117191533298916,
      "loss": 1.1099,
      "step": 1900
    },
    {
      "epoch": 0.589253489485508,
      "grad_norm": 0.1999792903661728,
      "learning_rate": 0.00016910686628807435,
      "loss": 1.1096,
      "step": 2000
    },
    {
      "epoch": 0.6187161639597835,
      "grad_norm": 0.2341824173927307,
      "learning_rate": 0.00016704181724315953,
      "loss": 1.0983,
      "step": 2100
    },
    {
      "epoch": 0.6481788384340589,
      "grad_norm": 0.29200708866119385,
      "learning_rate": 0.00016497676819824474,
      "loss": 1.0867,
      "step": 2200
    },
    {
      "epoch": 0.6776415129083343,
      "grad_norm": 0.2948332130908966,
      "learning_rate": 0.0001629117191533299,
      "loss": 1.095,
      "step": 2300
    },
    {
      "epoch": 0.7071041873826096,
      "grad_norm": 0.2098890095949173,
      "learning_rate": 0.00016084667010841507,
      "loss": 1.1093,
      "step": 2400
    },
    {
      "epoch": 0.736566861856885,
      "grad_norm": 0.2625705897808075,
      "learning_rate": 0.00015878162106350028,
      "loss": 1.0827,
      "step": 2500
    },
    {
      "epoch": 0.7495304386255662,
      "eval_loss": 0.9819775223731995,
      "eval_runtime": 52.0599,
      "eval_samples_per_second": 57.626,
      "eval_steps_per_second": 3.611,
      "step": 2544
    },
    {
      "epoch": 0.7660295363311604,
      "grad_norm": 0.5727604627609253,
      "learning_rate": 0.00015671657201858546,
      "loss": 1.0798,
      "step": 2600
    },
    {
      "epoch": 0.7954922108054359,
      "grad_norm": 0.2152143269777298,
      "learning_rate": 0.00015465152297367062,
      "loss": 1.0892,
      "step": 2700
    },
    {
      "epoch": 0.8249548852797113,
      "grad_norm": 0.23861098289489746,
      "learning_rate": 0.00015258647392875582,
      "loss": 1.0625,
      "step": 2800
    },
    {
      "epoch": 0.8544175597539867,
      "grad_norm": 0.21041280031204224,
      "learning_rate": 0.000150521424883841,
      "loss": 1.0978,
      "step": 2900
    },
    {
      "epoch": 0.8838802342282621,
      "grad_norm": 0.22808173298835754,
      "learning_rate": 0.0001484563758389262,
      "loss": 1.06,
      "step": 3000
    },
    {
      "epoch": 0.9133429087025374,
      "grad_norm": 0.278868705034256,
      "learning_rate": 0.00014639132679401137,
      "loss": 1.0578,
      "step": 3100
    },
    {
      "epoch": 0.9428055831768128,
      "grad_norm": 0.21314826607704163,
      "learning_rate": 0.00014432627774909655,
      "loss": 1.0688,
      "step": 3200
    },
    {
      "epoch": 0.9722682576510883,
      "grad_norm": 0.27056702971458435,
      "learning_rate": 0.00014226122870418173,
      "loss": 1.0659,
      "step": 3300
    },
    {
      "epoch": 0.9993739181674216,
      "eval_loss": 0.9574617147445679,
      "eval_runtime": 51.4813,
      "eval_samples_per_second": 58.274,
      "eval_steps_per_second": 3.652,
      "step": 3392
    },
    {
      "epoch": 1.0014731337237137,
      "grad_norm": 0.23835736513137817,
      "learning_rate": 0.0001401961796592669,
      "loss": 1.0615,
      "step": 3400
    },
    {
      "epoch": 1.0309358081979891,
      "grad_norm": 0.2000448852777481,
      "learning_rate": 0.0001381311306143521,
      "loss": 1.0555,
      "step": 3500
    },
    {
      "epoch": 1.0603984826722646,
      "grad_norm": 0.2815561890602112,
      "learning_rate": 0.00013606608156943728,
      "loss": 1.0523,
      "step": 3600
    },
    {
      "epoch": 1.08986115714654,
      "grad_norm": 0.24477612972259521,
      "learning_rate": 0.00013400103252452248,
      "loss": 1.0417,
      "step": 3700
    },
    {
      "epoch": 1.1193238316208154,
      "grad_norm": 0.27126798033714294,
      "learning_rate": 0.00013193598347960764,
      "loss": 1.0551,
      "step": 3800
    },
    {
      "epoch": 1.1487865060950908,
      "grad_norm": 0.2197243720293045,
      "learning_rate": 0.00012987093443469282,
      "loss": 1.0335,
      "step": 3900
    },
    {
      "epoch": 1.1782491805693662,
      "grad_norm": 0.23050114512443542,
      "learning_rate": 0.00012780588538977803,
      "loss": 1.0374,
      "step": 4000
    },
    {
      "epoch": 1.2077118550436416,
      "grad_norm": 0.32466232776641846,
      "learning_rate": 0.0001257408363448632,
      "loss": 1.0391,
      "step": 4100
    },
    {
      "epoch": 1.237174529517917,
      "grad_norm": 0.2418416142463684,
      "learning_rate": 0.00012367578729994836,
      "loss": 1.0514,
      "step": 4200
    },
    {
      "epoch": 1.2489595993076272,
      "eval_loss": 0.9361329674720764,
      "eval_runtime": 51.4347,
      "eval_samples_per_second": 58.326,
      "eval_steps_per_second": 3.655,
      "step": 4240
    },
    {
      "epoch": 1.2666372039921923,
      "grad_norm": 0.2741515040397644,
      "learning_rate": 0.00012161073825503357,
      "loss": 1.0472,
      "step": 4300
    },
    {
      "epoch": 1.296099878466468,
      "grad_norm": 0.2923852205276489,
      "learning_rate": 0.00011954568921011875,
      "loss": 1.0334,
      "step": 4400
    },
    {
      "epoch": 1.325562552940743,
      "grad_norm": 0.35512977838516235,
      "learning_rate": 0.00011748064016520392,
      "loss": 1.046,
      "step": 4500
    },
    {
      "epoch": 1.3550252274150185,
      "grad_norm": 0.2638174891471863,
      "learning_rate": 0.0001154155911202891,
      "loss": 1.0541,
      "step": 4600
    },
    {
      "epoch": 1.384487901889294,
      "grad_norm": 0.1990700215101242,
      "learning_rate": 0.0001133505420753743,
      "loss": 1.0281,
      "step": 4700
    },
    {
      "epoch": 1.4139505763635694,
      "grad_norm": 0.40526771545410156,
      "learning_rate": 0.00011128549303045948,
      "loss": 1.0369,
      "step": 4800
    },
    {
      "epoch": 1.4434132508378448,
      "grad_norm": 0.45833131670951843,
      "learning_rate": 0.00010922044398554465,
      "loss": 1.0454,
      "step": 4900
    },
    {
      "epoch": 1.4728759253121202,
      "grad_norm": 0.25350552797317505,
      "learning_rate": 0.00010715539494062986,
      "loss": 1.0268,
      "step": 5000
    },
    {
      "epoch": 1.4988030788494826,
      "eval_loss": 0.9258203506469727,
      "eval_runtime": 51.4703,
      "eval_samples_per_second": 58.286,
      "eval_steps_per_second": 3.653,
      "step": 5088
    },
    {
      "epoch": 1.5023385997863956,
      "grad_norm": 0.2686302661895752,
      "learning_rate": 0.00010509034589571502,
      "loss": 1.0192,
      "step": 5100
    },
    {
      "epoch": 1.531801274260671,
      "grad_norm": 0.21779775619506836,
      "learning_rate": 0.0001030252968508002,
      "loss": 1.0199,
      "step": 5200
    },
    {
      "epoch": 1.5612639487349464,
      "grad_norm": 0.2648437023162842,
      "learning_rate": 0.00010098089829633455,
      "loss": 1.0354,
      "step": 5300
    },
    {
      "epoch": 1.5907266232092219,
      "grad_norm": 0.2271661013364792,
      "learning_rate": 9.891584925141973e-05,
      "loss": 1.0167,
      "step": 5400
    },
    {
      "epoch": 1.6201892976834973,
      "grad_norm": 0.26109424233436584,
      "learning_rate": 9.685080020650491e-05,
      "loss": 1.0186,
      "step": 5500
    },
    {
      "epoch": 1.6496519721577725,
      "grad_norm": 0.2688729465007782,
      "learning_rate": 9.480640165203925e-05,
      "loss": 1.0103,
      "step": 5600
    },
    {
      "epoch": 1.6791146466320481,
      "grad_norm": 0.31903645396232605,
      "learning_rate": 9.274135260712442e-05,
      "loss": 1.0087,
      "step": 5700
    },
    {
      "epoch": 1.7085773211063233,
      "grad_norm": 0.20849956572055817,
      "learning_rate": 9.067630356220961e-05,
      "loss": 1.0074,
      "step": 5800
    },
    {
      "epoch": 1.738039995580599,
      "grad_norm": 0.23431895673274994,
      "learning_rate": 8.86112545172948e-05,
      "loss": 1.0013,
      "step": 5900
    },
    {
      "epoch": 1.748646558391338,
      "eval_loss": 0.9150933623313904,
      "eval_runtime": 51.4683,
      "eval_samples_per_second": 58.288,
      "eval_steps_per_second": 3.653,
      "step": 5936
    },
    {
      "epoch": 1.7675026700548742,
      "grad_norm": 0.21204544603824615,
      "learning_rate": 8.654620547237998e-05,
      "loss": 1.0052,
      "step": 6000
    },
    {
      "epoch": 1.7969653445291498,
      "grad_norm": 0.2429008185863495,
      "learning_rate": 8.45018069179143e-05,
      "loss": 1.0207,
      "step": 6100
    },
    {
      "epoch": 1.826428019003425,
      "grad_norm": 0.23604485392570496,
      "learning_rate": 8.243675787299949e-05,
      "loss": 1.0163,
      "step": 6200
    },
    {
      "epoch": 1.8558906934777004,
      "grad_norm": 0.2765907347202301,
      "learning_rate": 8.037170882808467e-05,
      "loss": 1.0143,
      "step": 6300
    },
    {
      "epoch": 1.8853533679519758,
      "grad_norm": 0.23725056648254395,
      "learning_rate": 7.830665978316985e-05,
      "loss": 1.0155,
      "step": 6400
    },
    {
      "epoch": 1.9148160424262513,
      "grad_norm": 0.24572564661502838,
      "learning_rate": 7.624161073825504e-05,
      "loss": 0.9938,
      "step": 6500
    },
    {
      "epoch": 1.9442787169005267,
      "grad_norm": 0.2256300151348114,
      "learning_rate": 7.417656169334021e-05,
      "loss": 0.9921,
      "step": 6600
    },
    {
      "epoch": 1.973741391374802,
      "grad_norm": 0.236953005194664,
      "learning_rate": 7.211151264842541e-05,
      "loss": 1.0133,
      "step": 6700
    },
    {
      "epoch": 1.9984900379331934,
      "eval_loss": 0.9074710011482239,
      "eval_runtime": 51.4539,
      "eval_samples_per_second": 58.305,
      "eval_steps_per_second": 3.654,
      "step": 6784
    },
    {
      "epoch": 2.0029462674474274,
      "grad_norm": 0.44100072979927063,
      "learning_rate": 7.004646360351057e-05,
      "loss": 0.9895,
      "step": 6800
    },
    {
      "epoch": 2.032408941921703,
      "grad_norm": 0.20938335359096527,
      "learning_rate": 6.802271553949406e-05,
      "loss": 1.0253,
      "step": 6900
    },
    {
      "epoch": 2.0618716163959783,
      "grad_norm": 0.22740258276462555,
      "learning_rate": 6.595766649457925e-05,
      "loss": 1.0138,
      "step": 7000
    },
    {
      "epoch": 2.091334290870254,
      "grad_norm": 0.24738885462284088,
      "learning_rate": 6.389261744966444e-05,
      "loss": 0.9936,
      "step": 7100
    },
    {
      "epoch": 2.120796965344529,
      "grad_norm": 0.2455182671546936,
      "learning_rate": 6.184821889519876e-05,
      "loss": 1.0038,
      "step": 7200
    },
    {
      "epoch": 2.1502596398188047,
      "grad_norm": 0.2182292342185974,
      "learning_rate": 5.978316985028395e-05,
      "loss": 0.993,
      "step": 7300
    },
    {
      "epoch": 2.17972231429308,
      "grad_norm": 0.22856122255325317,
      "learning_rate": 5.771812080536914e-05,
      "loss": 1.0028,
      "step": 7400
    },
    {
      "epoch": 2.2091849887673556,
      "grad_norm": 0.23876242339611053,
      "learning_rate": 5.565307176045431e-05,
      "loss": 0.9984,
      "step": 7500
    },
    {
      "epoch": 2.238647663241631,
      "grad_norm": 0.297776997089386,
      "learning_rate": 5.3629323696437795e-05,
      "loss": 1.0072,
      "step": 7600
    },
    {
      "epoch": 2.248075719073399,
      "eval_loss": 0.9009906053543091,
      "eval_runtime": 51.4217,
      "eval_samples_per_second": 58.341,
      "eval_steps_per_second": 3.656,
      "step": 7632
    }
  ],
  "logging_steps": 100,
  "max_steps": 10185,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 2544,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 7.460913039468134e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
